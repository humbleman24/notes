### ollama

当使用ollama部署本地大模型的时候，首先需要下载ollama的客户端，可以直接到官网进行下载

然后在ollama的官网上找到自己想要的大模型，然后在终端使用命令 ollama run <model_name>
这个时候ollama会下载已量化的后的模型权重，并保存至本地，下一次运行的时候就不需要再下载
可以指定模型权重保存的地址（默认保存在C://Users//.ollama）下，更改需要配置环境变量然后重启电脑

ollama ps   -- 命令用于查看最近启动过的大模型，以及运行的硬件是什么（CPU / GPU）

### llama-factory

llama-factory 需要在python环境下运行，首先先将应用克隆至本地 

git clone --depth 1 https://github.com/hiyouga/LLaMA-Factory.git

cd LLaMA-Factory

配置所需的环境（记得切换虚拟环境）

pip install -e ".[torch,metrics]"

查看是否安装成功

!llamafactory-cli version



#### 原始模型直接推理

```
llamafactory-cli webchat \
    --model_name_or_path /media/codingma/LLM/llama3/Meta-Llama-3-8B-Instruct \
    --template qwen
```

webchat 表示使用的是网页端的llamafactory UI

model_name_or_path 可以到modelscope或者huggingface上下载权重后，将路径作为参数传入，表示使用的是本地的模型

template  选择对应的prompt的格式，可以到llamafactory的github官网上查找对应的参数值



##### 微调命令
```
llamafactory-cli train --stage sft --do_train --model_name_or_path D:\models\Qwen2.5-7B-Instruct
 --dataset ruozhi --dataset_dir D:\LLaMA-Factory\data --template qwen --finetuning_type lora --output_dir D:\info\progra
m\NLP\asm\fine-tune-output --cutoff_len 1024 --per_device_train_batch_size 2 --fp16 --plot_loss --num_train_epochs 5.0 --learning_rate 5e-5
```


 llamafactory-cli train \
    --stage sft \
    --do_train \
    --model_name_or_path /media/codingma/LLM/llama3/Meta-Llama-3-8B-Instruct \
    --dataset alpaca_gpt4_zh,identity,adgen_local \
    --dataset_dir ./data \
    --template llama3 \
    --finetuning_type lora \
    --output_dir ./saves/LLaMA3-8B/lora/sft \
    --overwrite_cache \
    --overwrite_output_dir \
    --cutoff_len 1024 \
    --preprocessing_num_workers 16 \
    --per_device_train_batch_size 2 \
    --per_device_eval_batch_size 1 \
    --gradient_accumulation_steps 8 \
    --lr_scheduler_type cosine \
    --logging_steps 50 \
    --warmup_steps 20 \
    --save_steps 100 \
    --eval_steps 50 \
    --evaluation_strategy steps \
    --load_best_model_at_end \
    --learning_rate 5e-5 \
    --num_train_epochs 5.0 \
    --max_samples 1000 \
    --val_size 0.1 \
    --plot_loss \
    --fp16

##### 训练     

```
llamafactory-cli train --stage sft --do_train --model_name_or_path /root/autodl-tmp/Meta-Llama-3-8B-Instruct --dataset ruozhi --dataset_dir /root/autodl-tmp/LLaMA-Factory/data --template llama3 --finetuning_type lora --output_dir /root/prompt1 --cutoff_len 1024 --per_device_train_batch_size 2 --fp16 --plot_loss --num_train_epochs 1.0 --learning_rate 1e-4 --gradient_accumulation_steps 1
```



##### 使用

```
llamafactory-cli webchat --model_name_or_path /root/autodl-tmp/Qwen2.5-7B-Instruct --adapter_name_or_path /root/program/fine-tune-output --template qwen --finetuning_type lora
```



##### 评估

```
llamafactory-cli train \
    --stage sft \
    --do_predict \
    --model_name_or_path /root/autodl-tmp/Qwen2.5-7B-Instruct \
    --adapter_name_or_path /root/program/new-output  \
    --eval_dataset ruozhi_val \
    --dataset_dir /root/autodl-tmp/LLaMA-Factory/data \
    --template qwen \
    --finetuning_type lora \
    --output_dir /root/program/predict \
    --overwrite_cache \
    --overwrite_output_dir \
    --cutoff_len 1024 \
    --preprocessing_num_workers 16 \
    --per_device_eval_batch_size 32 \
    --max_samples 20 \
    --predict_with_generate
```



##### 导出
```
llamafactory-cli export \
    --model_name_or_path /root/autodl-tmp/Qwen2.5-7B-Instruct \
    --adapter_name_or_path /root/program/fine-tune-output  \
    --template qwen \
    --finetuning_type lora \
    --export_dir /root/autodl-tmp/megred-model \
    --export_size 2 \
    --export_device cpu \
    --export_legacy_format False
```

