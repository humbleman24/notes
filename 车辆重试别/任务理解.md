## 任务的分类

不应该属于分类任务，否则的话，每次添加一个新的类别，最后的分类器就无法使用，对应的前面的网络学习的内容也失效了，这不是想要的结果。

问题的关键是计算两个图像的距离。一种方法是学习一个神经网络，输入两张照片，输出是他们的距离或者相似度。

这是实现的一个算法是一种One-shot learning，增加一个新类别只需要提供一个训练数据就行了。

但是这样的一个处理方式，存在这一个问题：我们可能需要从几百万甚至是几千万张图片中搜索可能的同一辆车辆，用神经网络进行两两计算是不太可能的。

### 学习Embedding

另一种方法就是使用Embedding的方式。用一个d维空间的向量来表示整个图像的信息。所以计算两张照片的距离就变成了两个向量的运算。

也就是我们可以提前讲库中的所有图片映射成为一个d维的向量，然后就简单的计算向量的距离就好了

但是为了学习到一个网络使得可以提取到图像的特征，我们可能要使用到分类器来辅助训练。然后我们会把softmax之前的某个全连接层作为图像的特征向量。这个向量就可以认为是图像的最本质的特征。

### 引入Triple loss & contrastive

当然，如果使用一个分类的任务来间接地学习到一个向量，这个向量可能更加适用于分类，而不见得适用于距离的计算。

所以我们引入了Triple Loss的方式，来学习特征向量

简单介绍一下Triple Loss的公式，当然这个也不一定就是对的

首先要理解，我们的特征向量要增加一个约束，这些向量在d维的空间上应该是要有有相同的长度，都在半径为1的d维超球面上，也就是$||f(x)||_2=1$ 

接下来我们要选择3张图片也就是: $x^a, x^p, x^n$， anchor图像，positive图像，negative图像

我们期望它满足的条件如下：  $|f(x^a) - f(x^p)|_2^2 + \alpha < |f(x^a) - f(x^n)|_2^2$ 

意思就是同一辆车的图片的距离再加上一个margin $\alpha$ 的距离，仍要小于不同车辆图片的距离。

对应到Loss的公示上，我们不能表达为一个不等式，所以处理为下面的公式：
$$
L = \sum_iReLU(|f(x^a) - f(x^p)|_2^2 + \alpha - |f(x^a) - f(x^n)|_2^2)
$$
 意思就是，如果相同车辆的照片的Embedding的距离加上$\alpha$小于不同的车辆，那么就没有loss，不需要计算了，否则loss就是他们的差值，并且差值越大损失越大！

#### 图像的分组

如果想遍历所有的组合，是比较不可能的一个事情，因此只能挑选其中的一部分来进行训练。我们怎么挑选呢？

最简单的随机挑选，但这并不好

更好的办法就是挑选“难”的问题，最具有代表性的选择

给定一个anchor图像，我们想找最远的正样本，最近的负样本

但是如果所有都用最难的样本来训练还是会有一定问题的，你的函数无法学习到一个合理的参数。

所以必须从易到难，先从一些容易的问题上引导参数有一个大致正确的方向，然后再用困难的问题来学习更加细微喝tricky的细节。可以称为curriculum learning

两个方法：

- 离线的在某个子集上使用最新保持的模型选择argmin和argmax
- 在线的在一个大的mini-batch里使用最新的模型寻找argmin和argmax

第一种方法是把argmin和argmax局限与一个子集，这样可以避免**计算不可行的问题**，同时随着模型越来越准确，它挑选的问题也越来越难

第二种方法则要求mini-batch比较大，否则如果里面都是容易的问题，或者太难的问题就不好了

为了保证正样本的数量，我们要求每个mini-batch里面至少有一定量的照片是同一类的。对于一个给定的anchor，需要使用所有的正样本，但是负样本要选择整个mini-batch中最困难的一个

- 随机的选择40张的一张作为anchor
- 随机选择40张的另外一张作为正样本
- 使用当前的模型参数，在所有(mini-batch)负样本中选择距离anchor最近的作为负样本

who is next

